# 海量数据处理总结

## 案例

### 1 提取出某日访问百度次数最多的某个ip

解决方案：从访问百度的日志中逐个提取对应的`ip`（`ip`为32位的，最多有2^32个`ip`），并采用映射的方法，比如模1000，把`ip`地址映射到1000个文件中，再通过hash_map对每个小文件中`ip`出现的频率进行统计，找到出现频率最大的`ip`以及其对应的频率。最后，从这1000个频率中找到频率最大的`ip`，即为所求。

处理方法：`Hash`分而治之 + `hash_map/bit-map`(2^32 bit = 512M)

### 2 统计最热门的10个查询串

> 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
>
> 假设目前有一千万个记录（去重后，总条数不超过3百万个），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

预计算：1 G = 1000 M = 1000 000 K = 1000 000 000 B / 255 = 4000 000个

解决方案：首先，由于总条数不超过3百万个，且1G可容纳4百万查询串，可用`hash_map`统计每个查询串出现的次数。然后，借助堆找出`Top K`，时间复杂度为`NlogK`。我们需要维护一个小顶堆，遍历所有字符串出现的频率，如果频率大于堆顶元素，则交换元素并调整堆，遍历完后堆中保留的查询串，即为所求。

处理方法：`hash_map `+ 堆

### 3 统计频数最高的100个词

> 有一个1G大小的文件，里面每一行是一个词，词的大小不超过16Byte，内存限制1M。返回频数最高的100个词。

预计算：1 M = 2^10 K = 2^20 B / 2^4 = 2 ^ 16个

解决方案：顺序读取文件，对于每一个词x，取`hash(x)%5000`，将所有的单词放到不同的文件中，此时每个文件大概200kb左右。（如果某个单词数量过大，文件超过1M大小，则继续按照上述方法进行切分，直到分解得到的小文件的大小都不超过1M）。**选取一个文件利用hash_map或者trie树统计每一个单词的频率，并使用长度为K的小顶堆记录当前频率前100的单词**，依次对剩余的文件按照上述策略进行处理。遍历完所有文件后，堆中的数据即为所求。

处理方法：`hash`分而治之 + `hash_map/trie`树 + 堆

### 4 大文件数据排序

> 有10个文件，每个1G，每个文件的每一行存放的都是用户的`query`，且每一个文件的`query`都可能重复，须要按照query的频率进行排序。

解决方案：顺序读取10个文件，按照`hash(query)%10`的结果将`query`写入到另外10个文件中。这样新生成的文件每个的大小约为1G。此时需要一台内存在2G左右的机器，依次对用`hash_map(query, query_count)`来统计每个`query`出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应query输出到文件中，这样就得到了10个排好序的文件。最后对这10个文件进行归并排序（外排序，多路归并排序）。

处理方法：`hash`分而治之 + `hash_map` + 堆 + 外排序

### 5 找出大文件的交集

> 给定a、b两个文件，各存放50亿个`url`，每个`url`各占64字节，没存限制4G，找出a、b文件共同的`url`？

解决方案1：分而治之。遍历文件a，对每个url求取`hash(url)%1000`，然后根据所取得的值将url分别存储到1000个小文件中（记为`a0，a1，...，a999`）。每个小文件大约`300M`。

遍历文件b，采取相同hash策略，将b文件拆分为1000小文件（记为`b0，b1，...，b999`）。

上述处理后，所有可能相同的url都在对应的小文件（`a0vsb0，a1vsb1，...，`）中，不对应的小文件不可能有相同的url。最后针对每组小文件找出相同的url即可。

解决方案2：`Bloom filter`（有一定的错误率）。4G内存（4 000 000 000 * 8 = 320亿bit）。将其中一个文件中的`url`使用`Bloom filter`映射到`bitmap`上。然后，遍历另一个文件的`url`，检查是否存在即可。

处理方法：`hash`分而治之 + `hash_map`，`Bloom filter`（有一定的错误率）

### 6 找出不重复的数字

> 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。

解决方案1：分而治之。将这2.5亿个整数按照一定的hash策略，分配到内存可容忍的大小，并找出每一个文件中的不重复数字。

解决方案2：`2-BitMap`。消耗内存2^32 * 2 / 8 = 1G左右内存。其中每个数分配2bit，00表示不存在，01表示出现过一次，10表示多次。然后扫描这2.5亿个整数，查看`bitmap`中相对应位，如果是00变01，01变10，10保持不变。最后，遍历bitmap进行数据输出即可。

处理方法：`hash`分而治之，`2-bitmap`

### 7 判断数字是否存在

> 给40亿个不重复的`unsigned int`的整数，没排过序，然后再给一个数，如何快速判定这个数是否存在？

解决方案1：`BitMap`。用1bit表示数值是否存在，需要内存2^32 / 8 = 512M内存。其中一个bit代表一个`unsigned int`的值，读入40亿个数，设置相应的bit位，读入要查询的数，查看相应的bit位是否为1，为1则表示存在，为0则表示不存在。（桶排序的思想）

解决方案2：分而治之。按照最高位的0 1进行拆分文件。判定目标数最高位是0还是1，然后确定目标位于哪个文件中。再判定次高位，并接着进入相应的文件中再查找...以此类推，就可以查找到目标了。相当于二分查找。

处理方法：`bit-map`，二分思想-分而治之

### 8 多机器分布`TOP`问题

> 海量数据分布在100台电脑上，如何高效统计这批数据的`TOP10`。

解决方案：针对每台机器利用小顶堆找出`top10`。汇总所有机器的数据，总数1000个，再次利用小顶堆，遍历数值，即为所求。

处理方法：`mapreduce`+堆

## 处理方法总结

### 1 `Bloom Filter`

适用范围：（有一定的错误率）可以用来实现数据字典、数据的判重、求交集。

### 2 `Hashing`

适用范围：快速查找，通常需要将全部数据加载到内存。

碰撞处理：链地址法；开放定址法；双重`hash`法

### 3 `Bit-map`

适用范围：可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下

基本原理及要点：适用`bit`数组标识某些元素是否存在

### 4 堆

适用范围：海量数据前n大，并且n比较小，堆可以放入到内存中。

### 5 双层桶划分

适用范围：第k大，中位数

基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，最后在一个可以接受的范围内运行。

### 6 数据库索引（B+树）

适用范围：大数据量的增删改查

### 7 倒排索引

适用范围：搜索引擎，关键字查询

基本原理及要点：一种索引方法，被用来存储在全文搜索下某个单词在一个文档或一组文档中的存储位置的映射。

> 以英文为例，下面是要被索引的文本： `T0 = "it is what it is" T1 = "what is it" T2 = "it is a banana"  `
>
> 我们就能得到下面的反向文件索引：
>
> `	"a": {2} "banana": {2} "is": {0, 1, 2} "it": {0, 1, 2} "what": {0, 1}`
>
> 检索的条件"what","is"和"it"将对应集合的交集。  

问题实例：文档检索系统，查询那些文件包含了某单词，比如关键词搜索。

### 8 外排序

适用范围：大数据排序，去重

基本原理及要点：外排序的归并方法，置换选择败者树原理，最优归并树。

### 9 `Trie`树

适用范围：数据量大，重复多，但是数据种类小可以放入内存

基本原理及要点：实现方式，节点孩子的标识方法

扩展：**压缩实现**

### 10 分布式处理 `mapreduce`

适用范围：数据量大，但是数据种类小可以放入内存

基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约

> 经典问题分析：
>
> 　　上千万or亿数据（有重复），统计其中出现次数最多的前N个数据,分两种情况：可一次读入内存，不可一次读入。
>
> 　　可用思路：`trie`树+堆，数据库索引，划分子集分别统计，`hash`，分布式计算，近似统计，外排序
>
> 　　所谓的是否能一次读入内存，**实际上应该指去除重复后的数据量**。如果去重后数据可以放入内存，我们可以为数据建立字典，比如通过 `map`，`hash_map`，`trie`，然后直接进行统计即可。当然在更新每条数据的出现次数的时候，我们可以利用一个堆来维护出现次数最多的前N个数据，当然这样导致维护次数增加，不如完全统计后在求前N大效率高。
>
> 　　如果数据无法放入内存。一方面我们可以考虑上面的字典方法能否被改进以适应这种情形，可以做的改变就是将字典存放到硬盘上，而不是内存，这可以参考数据库的存储方法。
>
> 　　当然还有更好的方法，就是可以采用分布式计算，基本上就是`map-reduce`过程，首先可以根据数据值或者把数据`hash(md5)`后的值，将数据按照范围划分到不同的机子，最好可以让数据划分后可以一次读入内存，这样不同的机子负责处理各种的数值范围，实际上就是`map`。得到结果后，各个机子只需拿出各自的出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是`reduce`过程。
>
> 　　实际上可能想直接将数据均分到不同的机子上进行处理，这样是无法得到正确的解的。因为一个数据可能被均分到不同的机子上，而另一个则可能完全聚集到一个机子上，同时还可能存在具有相同数目的数据。比如我们要找出现次数最多的前100个，我们将1000万的数据分布到10台机器上，找到每台出现次数最多的前 100个，归并之后这样不能保证找到真正的第100个，因为比如出现次数最多的第100个可能有1万个，但是它被分到了10台机子，这样在每台上只有1千个，假设这些机子排名在1000个之前的那些都是单独分布在一台机子上的，比如有1001个，这样本来具有1万个的这个就会被淘汰，即使我们让每台机子选出出现次数最多的1000个再归并，仍然会出错，因为可能存在大量个数为1001个的发生聚集。因此不能将数据随便均分到不同机子上，而是要根据hash 后的值将它们映射到不同的机子上处理，让不同的机器处理一个数值范围。
>
> 　   而外排序的方法会消耗大量的IO，效率不会很高。而上面的分布式方法，也可以用于单机版本，也就是将总的数据根据值的范围，划分成多个不同的子文件，然后逐个处理。处理完毕之后再对这些单词的及其出现频率进行一个归并。实际上就可以利用一个外排序的归并过程。  