## 1.讲讲进程、线程，以及Go  goroutine
- 进程和线程的OS级别的 协程是用户态的
线程是具体执行者 进程负责为线程分配执行需要的资源
起到资源隔离作用
- 线程是调度单元
- 别的语言也有协程 比如yied
- 可以再说深一些，比如进程和线程哪些资源是共用的，哪些是独占的
- 先从进程和线程说起吧，应该都知道，进程是资源的封装单位，线程是操作系统的调度单位
- 一个程序至少有一个进程,一个进程至少有一个线程
- os 如何管理进程的，pcb 里大概存了些啥
- 进程调度也是维护可用进程队列的
- 我看网上资料将go 的goroutine 其实是用户级线程，相当于是用户级实现的线程库，对于cpu 来讲是不可见的，那用户级线程对cpu不可见的话，是怎么自己完成切换和调度的
- 为什么协程 是用户态?
用户态和内核态的区别和作用分别是什么？
- 因为携程由用户进程调度
在用户空间运行
- 调度的时候会进行指令切换。用户态切换到内核态，先把现在的进程信息保存起来，然后切换指令，再把将要执行的信息加载到内存，然后CPU再执行
- 这个得说明系统调用是干嘛的
用户态通过系统调用陷入内核态
喜兄弟说得对，只有内核才能调用系统硬件
- 如果我监听 键盘输入。
- 用户通过系统调用进入内核进行操作
- 内核空间 都是中断陷入进去的
- 这一操作。状态怎么转换的？
- 触发中断
硬中断
- **有没有调用system.call就是用户和内核分界线**
- 通过信号发生中断，根据一个编号啥的，进行指定的系统调用
- 什么叫系统调用
- 系统调用是用户操作内核的函数
- 个人理解，就拿线程和进程来说吧，两者关心的其实只有mmap，而mamp的实际指向的内存区域，只有陷入内核态才能发生改变，这里就限制了，无论线程和进程，如果想要进入实际内存，就只能通过内核
- 「 江边一只鸡: 个人理解，就拿线程和进程来说吧，两者关心的其实只有mmap，而mamp的实际指向的内存区域，只有陷入内核态才能发生改变，这里就限制了，无论线程和进程，如果想要进入实际内存，就只能通过内核 」
这块儿之间看过清华一教授的操作系统公开课里有讲，为了限制不同程序之间的访问能力，防止获取别的程序的内存数据，或者获取外围设备的数据，为了起到保护作用
目前问题点有以下：
讲讲进程、线程，以及Go  goroutine
进程和线程哪些资源是共用的，哪些是独占的
os 如何管理进程的，pcb 里大概存了些啥
用户态和内核态的区别和作用分别是什么？
-  就拿linux来说，线程和进程本质上都是一个个task，不同之处就是线程之间共享了task之间的堆和全局变量等资源，轻量级线程就是如此，至于goroutinue，这就是线程资源进一步复用的产物了
- **做goroutine池是否合理**
- 特殊场景下，限制数量还是需要的
协成多了cpu在调度上花费很多，目前正在做一个长连接接入服务，一条连接有两个协成分别进行读写，没请求的话单机能抗400w连接，但是实际场景是一条连接维持20s左右，一条连接平均发1次请求，结果一台机子只能抗住30w连接，qps也才1w多，pprof跑了下，调度占了快一半了。我准备换成这个框架看下效果
- **你大量创建的时候。他还来不及复用。 只能创建g 和sudog**
然后你创建的g 变成空闲的时候 是不会被回收的
但是 调度的很多地方都会遍历全局。
- go我的理解就是大量的函数调用，但是这个goroutinue却是中心单线程调度的，这就是goroutine的瓶颈所在
- 比如你一秒创建10万个。肯定来不及复用。 都是创建新的goroutine.
- 那这些大量创建的GR 什么时候会被回收呢
- 然后 可能这10万个 就一直在全局的 复用池了。
- 意思是，假设，我有500个链接，读写各一个 gr， 总共 100个。 但是底层其实没有 100个，会复用？
- 不会被回收。
- 这就吓人了 如果不限制数量 一个峰值打上去 后续都影响了
- 对。所以一般会控制数量
- 防止瞬间打高。
- 取决于你的机器资源。
- **先不说池了会不会快。快多少。**
这么玩 go官方知道吗
费了老大力气。让你直接go 你偏偏用c的线程池。何必啊
就算真快。我都不用。
还不一定快。。
- 只要防止服务瞬间请求过大。这属于服务限流问题了。
只是因为Go goroutine的特性。导致我们需要控制一下gr 的数量。
- 我是这样想的，go本身有goroutine的复用，合理控制goroutine的生命周期就好
**https://taohuawu.club/high-performance-implementation-of-goroutine-pool**
- **可以速度翻下 gin iris beego grpc 搞池没， 绝逼没搞！**

## 2.设计题：亿级视频帖子，评论表如何设计，要有弹幕功能
-  这种造航母设计题一定要先理解场景才好下手
弹幕有一点就是不管是否发送成功，只要给发送者显示出来就算成功，所以系统设计考虑这一点
1.用户订阅一个房间的主题，朝这个房间发弹幕就是推送消息，消息允许丢失，别的用户通过订阅这个主题获取其他用户的弹幕消息
2.弹幕存贮的问题，直播我不太会，说一下我理解的”时间线“，弹幕按照时间线存储
3.回看的时候，弹幕消息以流的方式取出来和视频一起播放
- 对的，弹幕需要一个消息中继的地方，收集弹幕消息定时批量推送给用户
恩恩，要么满足时间条件要么满足最大值
视频流和弹幕最好不要脱节
直播的时候也是，流量大了，通过CDN分发出去
- 弹幕设计思路：
推：用户发送弹幕消息通过长连接发给类似broker的角色。
存：broker将弹幕消息批量刷盘，并推送给用户
取：用户通过长连接接收，broker推送过来的弹幕消息。
并发：长连接接收推送消息并发量千万级可以，亿级加机器？我没做过。
惊群：为什么会出现惊群效应呢？
- **视频的话是要丢CDN的，所以压力也不在server**
- 亿级呢，长连接怎么做，然后需要几个broker，broker之间的同步
干脆不同步了
- 所以根本不需要做存储 那么核心问题就是怎么维持长链接了
对于维持无状态的长链接是比较简单的问题了 注意是无状态的
假如是一亿 按照用户ID进行128取模数 那意味还不到一百万
- 为什么要128
- 没啥讲究 就是为了模数对称 方便扩容
理论一个 生产主备就好了
客户端那边做自动断线重连功能
不是一个broker 是多个broker 来分担这一亿连接
- **实时的弹幕消息用长连接，那历史消息呢？**
**弹幕这块儿怎么存储，能按视频的播放进度显示当时发弹幕的**
- 也有点类似kafka的offset
不过这个offset一次跳一批，不是一条条跳
- @阿郎 按理来说用流的方式取弹幕消息不是更好
- 看视频app 的弹幕是根据进度条，相对时间记录弹幕内容
- 「 懒懒: 存文件吗？那新增的弹幕怎么写入文件 」
新增的时间线弹幕，例如回看的时候在开头插入
- 这个看设计了，要是弹幕多的话，谁知道保存没保存
- 「 阿郎: 回放新增的弹幕似乎很少看到保存的 」
不保存这种是直播场景，像视频播放这种，比如B站、爱奇艺、腾讯视频什么的，视频弹幕的场景
- **https://zhuanlan.zhihu.com/p/36024676**
看看别人怎么搞的。美图这个架构看着也不复杂
















